version: '3.8'

services:
  kibana:
    image: docker.elastic.co/kibana/kibana:8.12.2
    environment:
      - ELASTICSEARCH_HOSTS=http://elasticsearch:9200
      - ELASTICSEARCH_SERVICEACCOUNTTOKEN=${ELASTICSEARCH_SERVICEACCOUNTTOKEN}
      - XPACK_GUIDEDONBOARDING_ENABLED=false
      - XPACK_SECURITY_ENCRYPTIONKEY=something_at_least_32_characters
      - XPACK_ENCRYPTEDSAVEDOBJECTS_ENCRYPTIONKEY=something_different_at_least_32_chars
      - XPACK_REPORTING_ENCRYPTIONKEY=another_key_at_least_32_characters
      - XPACK_SECURITY_SECURECOOKIES=false
      - NODE_OPTIONS=--openssl-legacy-provider=0
    ports:
      - 5601:5601
    depends_on:
      - elasticsearch
    restart: unless-stopped

  zookeeper:
    image: confluentinc/cp-zookeeper:7.0.0
    container_name: zookeeper
    deploy:
      resources:
        limits:
          memory: 512M
    environment:
      ZOOKEEPER_HEAP_SIZE: 512
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
      ZOOKEEPER_INIT_LIMIT: 10
      ZOOKEEPER_SYNC_LIMIT: 5
      ZOOKEEPER_MAX_CLIENT_CNXNS: 100

    ports:
      - "2181:2181"
    healthcheck:
      test: ["CMD", "nc", "-z", "localhost", "2181"]
      interval: 5s
      timeout: 5s
      retries: 5
      start_period: 10s
    restart: always

  kafka1:
    image: confluentinc/cp-kafka:7.0.0
    container_name: kafka1
    depends_on:
      zookeeper:
        condition: service_healthy
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_CONNECTIONS_MAX_IDLE_MS: 300000
      KAFKA_SOCKET_REQUEST_MAX_BYTES: 104857600
      KAFKA_LISTENERS: INTERNAL://0.0.0.0:9092,EXTERNAL://0.0.0.0:19092
      KAFKA_ADVERTISED_LISTENERS: INTERNAL://kafka1:9092,EXTERNAL://localhost:19092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: INTERNAL:PLAINTEXT,EXTERNAL:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: INTERNAL
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 2
      KAFKA_DEFAULT_REPLICATION_FACTOR: 2
      KAFKA_MIN_INSYNC_REPLICAS: 1
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: 'true'

    ports:
      - "19092:19092"
    healthcheck:
      test:
        [
          "CMD-SHELL",
          "kafka-topics --bootstrap-server localhost:9092 --list || exit 1",
        ]
      interval: 10s
      timeout: 10s
      retries: 5
      start_period: 30s
    restart: always

  kafka2:
    image: confluentinc/cp-kafka:7.0.0
    container_name: kafka2
    depends_on:
      zookeeper:
        condition: service_healthy
    environment:
      KAFKA_BROKER_ID: 2
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_CONNECTIONS_MAX_IDLE_MS: 300000
      KAFKA_SOCKET_REQUEST_MAX_BYTES: 104857600
      KAFKA_LISTENERS: INTERNAL://0.0.0.0:9092,EXTERNAL://0.0.0.0:29092
      KAFKA_ADVERTISED_LISTENERS: INTERNAL://kafka2:9092,EXTERNAL://localhost:29092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: INTERNAL:PLAINTEXT,EXTERNAL:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: INTERNAL
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 2
      KAFKA_DEFAULT_REPLICATION_FACTOR: 2
      KAFKA_MIN_INSYNC_REPLICAS: 1
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: 'true'

    ports:
      - "29092:29092"
    healthcheck:
      test:
        [
          "CMD-SHELL",
          "kafka-topics --bootstrap-server localhost:9092 --list || exit 1",
        ]
      interval: 10s
      timeout: 10s
      retries: 5
      start_period: 30s
    restart: always

  kafka3:
    image: confluentinc/cp-kafka:7.0.0
    container_name: kafka3
    depends_on:
      zookeeper:
        condition: service_healthy
    environment:
      KAFKA_BROKER_ID: 3
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_CONNECTIONS_MAX_IDLE_MS: 300000
      KAFKA_SOCKET_REQUEST_MAX_BYTES: 104857600
      KAFKA_LISTENERS: INTERNAL://0.0.0.0:9092,EXTERNAL://0.0.0.0:39092
      KAFKA_ADVERTISED_LISTENERS: INTERNAL://kafka3:9092,EXTERNAL://localhost:39092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: INTERNAL:PLAINTEXT,EXTERNAL:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: INTERNAL
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 2
      KAFKA_DEFAULT_REPLICATION_FACTOR: 2
      KAFKA_MIN_INSYNC_REPLICAS: 1
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: 'true'

    ports:
      - "39092:39092"
    healthcheck:
      test:
        [
          "CMD-SHELL",
          "kafka-topics --bootstrap-server localhost:9092 --list || exit 1",
        ]
      interval: 10s
      timeout: 10s
      retries: 5
      start_period: 30s
    restart: always

  kafka-init:
    image: confluentinc/cp-kafka:7.0.0
    depends_on:
      kafka1:
        condition: service_healthy
      kafka2:
        condition: service_healthy
      kafka3:
        condition: service_healthy
    entrypoint: /bin/sh
    command:
      - -c
      - |
        echo 'Waiting for Kafka to be ready...'
        cub kafka-ready -b kafka1:9092 1 120
        cub kafka-ready -b kafka2:9092 1 120
        cub kafka-ready -b kafka3:9092 1 120
        echo 'Kafka brokers are up. Creating topics...'
        kafka-topics --create --bootstrap-server kafka1:9092 --topic connect-configs --replication-factor 2 --partitions 1 --if-not-exists --config cleanup.policy=compact
        kafka-topics --create --bootstrap-server kafka1:9092 --topic connect-offsets --replication-factor 2 --partitions 1 --if-not-exists --config cleanup.policy=compact
        kafka-topics --create --bootstrap-server kafka1:9092 --topic connect-status --replication-factor 2 --partitions 1 --if-not-exists --config cleanup.policy=compact
        kafka-topics --create --bootstrap-server kafka1:9092 --topic _confluent-controlcenter-7-0-0-command --replication-factor 2 --partitions 1 --if-not-exists
        kafka-topics --create --bootstrap-server kafka1:9092 --topic _confluent-controlcenter-7-0-0-metrics --replication-factor 2 --partitions 1 --if-not-exists
        echo 'Kafka topics created successfully!'
    restart: on-failure
    healthcheck:
      test: ["CMD-SHELL", "exit 0"] 
      interval: 5s
      timeout: 1s
      retries: 1
      start_period: 30s


  kafka-connect:
    image: confluentinc/cp-kafka-connect:7.0.0
    container_name: kafka-connect
    depends_on:
      kafka1:
        condition: service_healthy
      kafka2: 
        condition: service_healthy
      kafka3:
        condition: service_healthy
      kafka-init:
        condition: service_healthy
    environment:
      CONNECT_BOOTSTRAP_SERVERS: kafka1:9092,kafka2:9092,kafka3:9092
      CONNECT_REST_PORT: 8083
      CONNECT_REST_ADVERTISED_HOST_NAME: kafka-connect
      CONNECT_GROUP_ID: "kafka-connect-group"
      CONNECT_CONFIG_STORAGE_TOPIC: "connect-configs"
      CONNECT_OFFSET_STORAGE_TOPIC: "connect-offsets"
      CONNECT_STATUS_STORAGE_TOPIC: "connect-status"
      CONNECT_CONFIG_STORAGE_REPLICATION_FACTOR: 2
      CONNECT_OFFSET_STORAGE_REPLICATION_FACTOR: 2
      CONNECT_STATUS_STORAGE_REPLICATION_FACTOR: 2
      CONNECT_KEY_CONVERTER: "org.apache.kafka.connect.storage.StringConverter"
      CONNECT_VALUE_CONVERTER: "org.apache.kafka.connect.json.JsonConverter"
      CONNECT_VALUE_CONVERTER_SCHEMAS_ENABLE: "false"
      CONNECT_INTERNAL_KEY_CONVERTER: "org.apache.kafka.connect.json.JsonConverter"
      CONNECT_INTERNAL_VALUE_CONVERTER: "org.apache.kafka.connect.json.JsonConverter"
      CONNECT_PLUGIN_PATH: "/usr/share/java,/usr/share/confluent-hub-components"
      CONNECT_REQUEST_TIMEOUT_MS: 120000
      CONNECT_RETRY_BACKOFF_MS: 500
    ports:
      - "8083:8083"
    restart: unless-stopped

  control-center:
    image: confluentinc/cp-enterprise-control-center:7.0.0
    hostname: control-center
    container_name: control-center
    depends_on:
      - kafka1
      - kafka2
      - kafka3
      - kafka-init
    ports:
      - "9021:9021"
    environment:
      CONTROL_CENTER_BOOTSTRAP_SERVERS: kafka1:9092,kafka2:9092,kafka3:9092
      CONTROL_CENTER_ZOOKEEPER_CONNECT: zookeeper:2181
      CONTROL_CENTER_INTERNAL_TOPICS_PARTITIONS: 1
      CONTROL_CENTER_MONITORING_INTERCEPTOR_TOPIC_PARTITIONS: 1
      CONFLUENT_METRICS_TOPIC_REPLICATION: 2
      CONTROL_CENTER_REPLICATION_FACTOR: 2
      PORT: 9021
    restart: unless-stopped

  kafka-ui:
    image: provectuslabs/kafka-ui
    container_name: kafka-ui
    ports:
      - 8080:8080
    environment:
      - KAFKA_CLUSTERS_0_NAME=local
      - KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS=kafka1:9092,kafka2:9092,kafka3:9092
      - KAFKA_CLUSTERS_0_CONSUMER_GROUPS=true
    depends_on:
      - kafka1
      - kafka2
      - kafka3
      - kafka-init
    restart: unless-stopped

  postgres:
    image: postgres
    container_name: postgres_container
    environment:
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: huynhnhatvuong1
      POSTGRES_DB: social
    ports:
      - "5432:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data
    restart: unless-stopped

  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:8.12.2
    container_name: elasticsearch
    environment:
      - discovery.type=single-node
      - xpack.security.enabled=true
      - ES_JAVA_OPTS=-Xms512m -Xmx512m
      - ELASTIC_PASSWORD=changeme
    ports:
      - "9200:9200"
    volumes:
      - elastic_data:/usr/share/elasticsearch/data
    restart: unless-stopped

  redis:
    image: redis
    container_name: redis
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
    restart: unless-stopped

  rabbitmq:
    image: rabbitmq:3-management
    container_name: rabbitmq
    ports:
      - "5672:5672"
      - "15672:15672"
    environment:
      RABBITMQ_DEFAULT_USER: guest
      RABBITMQ_DEFAULT_PASS: guest
    restart: unless-stopped

volumes:
  postgres_data:
    driver: local
  elastic_data:
    driver: local
  redis_data:
    driver: local